### **神经网络与深度学习期末复习材料**

#### **一、 目标检测 (Object Detection)**

**核心知识点**: IoU (交并比)、锚框 (Anchor Boxes)、损失函数构成、NMS (非极大值抑制)、数据集标注格式。

**例题 1.1**

> 在一个目标检测任务中，真实边界框（Ground Truth）的面积为 20。算法生成了两个预测框 A 和 B。A 框与真实框的交集面积为 15，B 框与真实框的交集面积为 10。请问 A 框和 B 框各自的 IoU 值是多少？哪个框的定位更准确？
> 
> **答案**:
> 
> - A 框 IoU = 15 / (20 + Area_A - 15)。由于 IoU 计算需要预测框面积，此处信息不足无法得出精确数值，但可以比较相对大小。
> - B 框 IoU = 10 / (20 + Area_B - 10)。
> - **解析**: 此题意在强调 IoU 的计算方式。若假设 A 和 B 预测框面积相同，则 A 框 IoU 更高，定位更准。但通常情况下，我们直接比较 IoU 值即可判断定位优劣。IoU 越高，定位越准确。

**例题 1.2**

> 假设一个目标检测模型使用 `scales = [0.7, 1.0]` 和 `ratios = [0.8, 1.25]` 来生成锚框。对于一个中心点固定的网格单元，总共会生成多少个不同的锚框？如果输入图像尺寸为 640x640，当 `scale=1.0` 且 `ratio=0.8` 时，该锚框的宽度和高度分别是多少？
> 
> **答案**:
> 
> - 总共生成 2 (scales) * 2 (ratios) = **4 个**锚框。
> - 锚框面积基准通常是 `640*640` 的一部分，但比例计算是独立的。`ratio = width / height = 0.8`，且 `scale=1.0` 意味着其面积与基准面积成比例。具体宽高为：设高度为 H，则宽度 W = 0.8H。实际数值取决于实现细节，但比例关系是确定的。
> - **解析**: 锚框总数由尺度和宽高比的笛卡尔积决定。宽高比直接决定了锚框的形状。

---

#### **二、 注意力机制与序列模型 (Attention & Sequence Models)**

**核心知识点**: RNN 的信息传递、马尔可夫性、注意力机制类比、Transformer 结构、自注意力机制、Seq2Seq 任务。

**例题 2.1 **

> 判断正误：在 Transformer 模型的编码器中，每个位置的词向量在经过多头自注意力层后，其最终表示只包含了与它直接相邻的词的信息。
> 
> **答案**: **错误 (F)**
> 
> - **解析**: 这正是 Transformer 相对于 RNN 的核心优势。自注意力机制允许序列中的任意两个位置直接交互，无论它们相距多远。因此，一个词的最终表示可以包含整个句子的上下文信息，而不仅仅是邻近词。

**例题 2.2**

> 以下哪些任务可以被建模为序列到序列（Seq2Seq）问题？
> A. 根据用户的历史购买记录，预测他下一次最可能购买的商品类别。
> B. 将一段法语文本翻译成德语文本。
> C. 给定一张街景图片，生成描述图片内容的句子。
> D. 对一封电子邮件进行分类，判断它是“工作”、“个人”还是“垃圾邮件”。
> 
> **答案**: **B, C**
> 
> - **解析**: Seq2Seq 的特点是输入和输出都是**序列**。A 是序列到单个标签（分类），D 也是分类任务。B（机器翻译）和 C（图像描述生成，可视为从图像特征序列到文本序列）是典型的 Seq2Seq 任务。

---

#### **三、 生成模型：扩散模型 (Diffusion Models)**

**核心知识点**: 扩散过程、去噪过程、提示词作用、训练目标、Stable Diffusion 的潜空间、FID 评估指标。

**例题 3.1**

> 关于 Stable Diffusion 模型，以下说法正确的是？
> A. 它直接在原始像素空间中进行加噪和去噪操作。
> B. 其训练目标是在给定带噪图像和时间步 t 的条件下，预测出原始清晰图像。
> C. 引入变分自编码器（VAE）将图像压缩到潜空间，大大降低了计算复杂度。
> D. FID 分数越高，说明生成的图像质量越好，越接近真实数据分布。
> 
> **答案**: **C**
> 
> - **解析**: A 错误，Stable Diffusion 在 VAE 编码后的**潜空间**中进行扩散。B 错误，其训练目标是预测**所添加的噪声**，而非直接预测原图。C 正确，这是 Stable Diffusion 的关键创新。D 错误，FID 分数**越低**越好。

**例题 3.2**

> 在扩散模型的训练过程中，对于一张清晰的训练图像，我们会随机选择一个时间步 `t`，然后向图像中添加噪声，得到一个带噪版本 `x_t`。此时，U-Net 网络的输入是什么？它的预测目标又是什么？衡量生成图像质量的 FID 指标，其数值大小与图像质量的关系是？
> 
> **答案**:
> 
> - **输入**: 带噪图像 `x_t`、时间步 `t`、以及（对于条件生成）文本提示的嵌入向量。
> - **预测目标**: 在时间步 `t` 所添加的**噪声**。
> - **FID 关系**: FID 值**越小**，生成图像的质量通常越高，与真实图像的分布越接近。
> - **解析**: 这是扩散模型训练的核心范式。FID 通过比较生成图像和真实图像在 Inception 网络特征空间中的分布距离来评估质量。

---

#### **四、 强化学习 (Reinforcement Learning)**

**核心知识点**: 强化学习 vs 监督学习、智能体决策的随机性、奖励延迟、Actor-Critic 框架、探索与利用。

**例题 4.1**

> 判断正误：在一个基于策略梯度的强化学习算法中，智能体在某个状态下选择动作的概率是由其策略网络（Actor）输出的。即使在完全相同的状态下，智能体也可能做出不同的动作，这是为了鼓励探索。
> 
> **答案**: **正确 (T)**
> 
> - **解析**: 策略梯度方法（如 Actor-Critic）学习的是一个**随机策略**，即 `π(a|s)`，表示在状态 `s` 下选择动作 `a` 的概率。决策时通过对这个概率分布进行采样来选择动作，这自然引入了随机性，是探索的一种形式。

**例题 4.2**

> 在使用 DQN（深度 Q 网络）训练一个玩 Atari 游戏的智能体时，以下哪些做法是合理的？
> A. 设计奖励函数，使得每当智能体得分时获得正奖励，生命值减少时获得负奖励。
> B. 智能体的 Q 网络直接输出在当前状态下每个可能动作的**期望累积回报**（Q 值）。
> C. 为了解决“灾难性遗忘”问题，DQN 使用了经验回放（Experience Replay）机制。
> D. 在训练初期，智能体应始终选择 Q 值最大的动作（贪婪策略），以尽快学习到最优行为。
> 
> **答案**: **A, B, C**
> 
> - **解析**: A 是设计奖励函数的常见方法。B 是 DQN 的基本原理。C 是 DQN 的关键技术之一。D 错误，在训练初期需要大量的**探索**（例如使用 ε-greedy 策略），不能总是贪婪地选择当前认为最好的动作，否则可能陷入次优策略。

---

#### **五、 卷积神经网络 (CNN) 基础**

**核心知识点**: 卷积操作（参数共享、输出尺寸计算）、池化、激活函数（ReLU）、经典网络（AlexNet, VGG, ResNet）、批量归一化、1x1 卷积。

**例题 5.1**

> 对于一个输入尺寸为 32x32x3（高 x 宽 x 通道）的彩色图像，使用一个 5x5 的卷积核，步幅（stride）为 2，填充（padding）为 1。请问输出特征图的空间尺寸（高和宽）是多少？该卷积层是否使用了参数共享？
> 
> **答案**:
> 
> - 输出尺寸 = `(32 - 5 + 2*1) / 2 + 1 = (32 - 5 + 2) / 2 + 1 = 29/2 + 1 = 14.5 + 1`。由于结果必须为整数，实际计算中会向下取整或报错，但根据公式，理想输出为 **15x15** (注：`(32+2-5)/2 + 1 = 29/2 + 1 = 14.5`，通常框架会处理为 15 或 14，此处按标准公式 `(W-F+2P)/S + 1` 计算，若结果非整则配置无效。假设有效，则为 15x15)。
> - **是**，使用了参数共享。同一个卷积核的权重在整个输入特征图上滑动并重复使用。
> - **解析**: 掌握输出尺寸计算公式 `(W - F + 2P) / S + 1` 是关键。参数共享是 CNN 的核心特性之一。

**例题 5.2 **

> ResNet 通过引入什么结构解决了深层网络训练困难的问题？VGG 网络偏好使用多个连续的 3x3 卷积层堆叠，这样做相比于使用一个大的卷积层（如 7x7）有什么好处（至少两点）？
> 
> **答案**:
> 
> - ResNet 引入了**残差连接/跳跃连接 (Residual/Skip Connection)**。
> - VGG 使用小卷积核的好处：
>   1. **减少参数量**：两个 3x3 卷积的感受野相当于一个 5x5 卷积，但参数量 `(3*3*C*C)*2 = 18C²` 远小于 `5*5*C*C = 25C²`。
>   2. **增加非线性**：多个卷积层之间可以插入更多的激活函数（如 ReLU），使模型具有更强的非线性表达能力。
> - **解析**: 残差连接让网络可以学习恒等映射，缓解了梯度消失。小卷积核堆叠是现代 CNN 设计的基石。

---

#### **六、 数据处理与模型训练技巧**

**核心知识点**: 图像增广（目的、方法）、微调（Fine-tuning）、数据集（ImageNet, COCO）、硬件依赖。

**例题 6.1 **

> 在对一个医学影像分类数据集进行微调（Fine-tuning）时，以下哪种做法是不恰当的？
> A. 使用在 ImageNet 上预训练好的 ResNet-50 作为骨干网络。
> B. 在训练、验证和测试阶段都应用随机水平翻转和旋转作为数据增强。
> C. 冻结骨干网络的前几层，只训练最后的全连接分类层和部分高层卷积层。
> D. 使用比从头训练（Training from scratch）更小的学习率。
> 
> **答案**: **B**
> 
> - **解析**: 数据增强（如翻转、旋转）**只能在训练阶段**使用，目的是增加训练数据的多样性。在验证和测试阶段，我们必须对原始、未修改的数据进行评估，以获得模型性能的真实、无偏估计。

**例题 6.2**

> COCO (Common Objects in Context) 数据集是计算机视觉领域的重要基准。以下关于 COCO 数据集的描述，哪些是正确的？
> A. 它主要提供图像级别的分类标签。
> B. 它为图像中的物体实例提供了边界框（Bounding Box）标注。
> C. 它还包含了像素级的实例分割（Instance Segmentation）掩码。
> D. 它只包含 20 个常见的物体类别。
> 
> **答案**: **B, C**
> 
> - **解析**: COCO 是一个**实例级**的数据集，不仅有边界框，还有精细的分割掩码，并且包含了 **80** 个物体类别。A 描述的是像 CIFAR-10 这样的分类数据集，D 描述的是 PASCAL VOC 数据集。

---

#### **七、 PyTorch 与神经网络基础**

**核心知识点**: Tensor、设备管理、自定义层、线性模型、激活函数、损失函数、优化器、过拟合与欠拟合。

**例题 7.1 **

> 在 PyTorch 中，要创建一个自定义的神经网络层，需要继承哪个基类？另外，为了防止模型在训练集上过拟合，以下哪些技术是有效的？
> A. `torch.nn.Layer`
> B. `torch.nn.Module`
> C. 增加更多的训练数据或使用数据增强。
> D. 使用更大的模型（增加层数或神经元数量）。
> E. 应用 Dropout 或权重衰减（L2 正则化）。
> 
> **答案**:
> 
> - 自定义层基类: **B. `torch.nn.Module`**
> - 防止过拟合的技术: **C, E**
> - **解析**: `nn.Module` 是所有神经网络模块的基类。增加数据和正则化技术（Dropout, 权重衰减）是应对过拟合的标准方法。而使用更大的模型（D）通常会**加剧**过拟合。

**例题 7.2 **

> 在 PyTorch 中，`torch.randn(3, 4)` 生成的张量元素服从什么分布？深度学习框架能够自动计算梯度的核心技术叫什么？在多层感知机（MLP）中，通常使用什么层将二维的图像数据展平成一维向量以输入到全连接层？
> 
> **答案**:
> 
> - **正态分布 (或高斯分布)**
> - **自动微分 (Automatic Differentiation)**
> - **展平层 (Flatten Layer)**
> - **解析**: 这些是 PyTorch 和神经网络中最基础的概念，务必熟练掌握。

---

希望这份复习材料能帮助您高效备考！祝您取得优异成绩！
